{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aac3cc7-ab94-4020-a4ca-fded9419506f",
   "metadata": {},
   "source": [
    "# Assessment Plan for ABET (6)\n",
    "\n",
    ":::{note} \n",
    "This section is primarily for instructor(s) and laboratory assistants.\n",
    ":::\n",
    "\n",
    ">ABET (6): an ability to develop and conduct appropriate experimentation, analyze and interpret data, and use engineering judgment to draw conclusions.\n",
    "\n",
    "## Assessment Set (3–4 graded activities)\n",
    "\n",
    "1. Pre-Lab Experimental Plan (individual; 1–2 pages or quiz form): Identifies objective, variables (independent/dependent/controlled), calibration, sampling plan, acceptance criteria, anticipated error sources.\n",
    "**Evidence:** develop.\n",
    "\n",
    "2. In-Lab Execution & Data Quality (TA/Instructor checklist during one anchor lab): Setup, calibration, safe procedure, adequate resolution, field notes/metadata.\n",
    "**Evidence:** conduct.\n",
    "\n",
    "3. Post-Lab Analysis Report/Notebook (individual; 3–5 pages): Appropriate analysis/modeling, uncertainty (replicates/propagation, residuals), interpretation, recommendation tied to criteria.\n",
    "**Evidence:** analyze & interpret + judgment.\n",
    "\n",
    "4. Practical Exam (mini-scenario) (individual): Design a quick test under constraints or analyze a messy dataset and make a defensible recommendation.\n",
    "**Evidence:** all facets under novelty/time.\n",
    "\n",
    "Use 3–4 of the above across 2–3 representative labs (e.g., calibration, flow/transport, open-ended troubleshooting) for triangulation.\n",
    "\n",
    "## Common Rubric (0–3 scale for all activities)\n",
    "\n",
    "**Performance Levels**\n",
    "\n",
    "- 3 — Exemplary: correct, justified, complete\n",
    "\n",
    "- 2 — Proficient: mostly correct; minor gaps\n",
    "\n",
    "- 1 — Developing: partial; notable gaps/weak justification\n",
    "\n",
    "- 0 — Beginning: missing/incorrect/unjustified\n",
    "\n",
    "**Criteria (with ABET mapping)**\n",
    "\n",
    "**C1. Experimental Design & Planning (develop)**\n",
    "\n",
    "- 3: Clear objective; variables identified; calibration plan; sampling strategy justified; acceptance criteria stated.\n",
    "\n",
    "- 2: Objective/variables clear; reasonable sampling; minor omissions.\n",
    "\n",
    "- 1: Vague variables or ad-hoc sampling; thin rationale.\n",
    "\n",
    "- 0: No coherent plan.\n",
    "\n",
    "**C2. Execution & Data Quality (conduct)**\n",
    "\n",
    "3: Correct setup; calibration executed/recorded; adequate resolution; complete metadata; safe procedure.\n",
    "\n",
    "2: Minor setup/doc issues; quality adequate.\n",
    "\n",
    "1: Notable setup/logging problems; questionable data quality.\n",
    "\n",
    "0: Unsafe/incorrect execution; unusable data.\n",
    "\n",
    "**C3. Analysis & Uncertainty (analyze)**\n",
    "\n",
    "- 3: Appropriate models/stats; uncertainty quantified; assumptions checked; units/error bars/residuals shown.\n",
    "\n",
    "- 2: Core analysis correct; uncertainty addressed but limited.\n",
    "\n",
    "- 1: Basic calculations only; little/no uncertainty treatment.\n",
    "\n",
    "- 0: Analysis incorrect/absent.\n",
    "\n",
    "**C4. Interpretation & Engineering Judgment (interpret + judgment)**\n",
    "\n",
    "- 3: Competing explanations weighed; links to principles; recognizes limits; recommendation balances performance/risk/constraints.\n",
    "\n",
    "- 2: Interpretation correct; reasonable recommendation; minor caveats missing.\n",
    "\n",
    "- 1: Describes plots literally; weak/unsupported recommendation.\n",
    "\n",
    "- 0: Misinterprets results; no decision.\n",
    "\n",
    "**C5. Conclusions & Communication (draw conclusions)**\n",
    "\n",
    "- 3: Conclusion answers objective; supported by data/uncertainty; clear figures/tables; correct units/sig figs; next steps.\n",
    "\n",
    "- 2: Mostly supported; minor clarity/format issues.\n",
    "\n",
    "- 1: Weak tie to evidence; unclear visuals.\n",
    "\n",
    "- 0: No conclusion or unrelated.\n",
    "\n",
    "**Suggested Weights by Activity**\n",
    "\n",
    "|Activity\t|C1\t|C2\t|C3\t|C4\t|C5|\n",
    "|-----------|---|---|---|---|---|\n",
    "|Pre-Lab Plan\t|40%\t|0%\t|20%\t|20%\t|20%|\n",
    "|In-Lab Execution Checklist\t|10%\t|70%\t|0%\t|0%\t|20%|\n",
    "|Post-Lab Analysis Memo\t|10%\t|0%\t|35%\t|35%\t|20%|\n",
    "|Practical Exam\t|20%\t|0%\t|30%\t|40%\t|10%|\n",
    "\n",
    "Score each criterion 0–3, apply the weights above per activity, then average across the 3–4 activities to get each student’s ABET(6) index (0–3).\n",
    "\n",
    "## Outcome Target & Reporting\n",
    "\n",
    "Target: ≥ 70% of students achieve ≥ 2.0 (Proficient) on the ABET(6) index; cohort mean ≥ 2.3.\n",
    "\n",
    "Report: cohort mean, median, standard deviation, and % ≥ 2.0.\n",
    "\n",
    "Close-the-loop note: If a criterion falls short (commonly C3 or C4), plan an instructional change (e.g., short pre-lab on uncertainty; mid-lab calibration check).\n",
    "\n",
    ":::{admonition} Representative Sample (ready text)\n",
    "\n",
    "Description of representative sample of assessed student work.\n",
    "This assessment of ABET outcome (6) draws on four graded artifacts from the laboratory course: (1) a pre-lab experimental plan (individual), (2) an in-lab execution & data-quality checklist scored by the TA/instructor during Lab [], (3) a post-lab analysis memo for Lab [], and (4) a practical exam mini-scenario. Each artifact is scored with the same five-criterion rubric (Design & Planning; Execution & Data Quality; Analysis & Uncertainty; Interpretation & Engineering Judgment; Conclusions & Communication) on a 0–3 scale with defined performance descriptors.\n",
    "\n",
    "A stratified sample (~20%) of students was selected across score quartiles. For each student in the sample, we include the pre-lab plan with rubric, the TA’s in-lab checklist, the analysis memo with annotated figures and rubric, and the practical exam response. Scores are summarized as an ABET(6) index (weighted average of rubric criteria across activities). This sample demonstrates the range from Beginning to Exemplary performance and supports the reported attainment statistics.\n",
    "\n",
    ":::\n",
    "\n",
    "## Instruments (templates)\n",
    "\n",
    "### In-Lab Execution Checklist (10 pts → maps to C2)\n",
    "\n",
    "☐ Setup matches plan/schematic (2)\n",
    "\n",
    "☐ Calibration performed & logged (2)\n",
    "\n",
    "☐ Sampling rate/duration as planned (2)\n",
    "\n",
    "☐ Field notes/metadata complete (2)\n",
    "\n",
    "☐ Safety & housekeeping (2)\n",
    "\n",
    "### Pre-Lab Plan Prompt (maps to C1/C3/C4/C5)\n",
    "\n",
    "Objective as a testable question\n",
    "\n",
    "Variables: independent/dependent/controlled\n",
    "\n",
    "Calibration: what/how/acceptance criteria\n",
    "\n",
    "Sampling plan (n, rate, duration) with rationale\n",
    "\n",
    "Anticipated error sources + mitigation/quantification\n",
    "\n",
    "Decision rule tied to engineering criteria\n",
    "\n",
    "### Post-Lab Analysis Memo Structure (maps to C3/C4/C5)\n",
    "\n",
    "Methods recap (what you actually did vs plan)\n",
    "\n",
    "Results with figures (units, error bars, residuals)\n",
    "\n",
    "Uncertainty (replicates/propagation; confidence on key parameter)\n",
    "\n",
    "Interpretation: alternatives; limitations\n",
    "\n",
    "Recommendation tied to criteria; next steps\n",
    "\n",
    "### Practical Exam Mini-Scenarios\n",
    "\n",
    "Design: “In 30 minutes with equipment list X, design a test to estimate ___ within ±5%. Justify n, rate, calibration, acceptance criteria.”\n",
    "\n",
    "Analyze & decide: “Given this dataset with outliers, fit ___, report parameter + uncertainty, and recommend pass/fail per spec ___. Justify.”\n",
    "\n",
    "## Logistics & Reliability\n",
    "\n",
    "Grader calibration: co-score ~10% of plans/memos; aim ≥80% agreement within ±1 rubric level per criterion.\n",
    "\n",
    "Archiving: store PDFs + rubric sheets for sampled students (by activity/semester).\n",
    "\n",
    "Administration: run the pre-lab and memo on two different labs; observe one anchor lab for the checklist; practical exam at end.\n",
    "\n",
    "## Quick Implementation (checklist)\n",
    "\n",
    "☐ Publish the rubric & weights on the lab site\n",
    "\n",
    "☐ Create submission templates (plan/memo) with headings matching criteria\n",
    "\n",
    "☐ Prepare TA checklist forms (paper or Google Form)\n",
    "\n",
    "☐ Set up a simple scoring sheet (columns: Student, Activity, C1–C5, weighted score; auto-compute ABET(6) index)\n",
    "\n",
    "☐ Define sampling method for the representative set (e.g., every 5th student + edge cases)\n",
    "\n",
    "## End of assessment plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761d9432-28b4-4fb3-b9fc-9a14bc00d9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Common Environment",
   "language": "python",
   "name": "python-my-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}